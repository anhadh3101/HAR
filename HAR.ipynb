{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOm44EYjNTp/olTfYrYSQ4l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anhadh3101/HAR/blob/main/HAR.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Importing necessary libraries"
      ],
      "metadata": {
        "id": "LA94ehtiAJbn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import tensorflow as tf\n",
        "from torchvision import transforms\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras import Model\n",
        "from keras.models import Sequential\n",
        "from keras.applications.vgg16 import VGG16"
      ],
      "metadata": {
        "id": "nrocpkC6qXlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading the dataset\n",
        "1. Add the training dataset's zip file to your google drive.\n",
        "2. Mount the google drive to the colab notebook by running the first code setion.\n",
        "3. Unzip the file to the local environment by running the second code section. (Set the path to the dataset accordingly)\n"
      ],
      "metadata": {
        "id": "Kqv0oVsJ90uO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7rYfD63a3Mu",
        "outputId": "a744717e-8334-4045-917d-3814828f7555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip gdrive/My\\ Drive/archive.zip"
      ],
      "metadata": {
        "id": "SiQHNamPdGU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing the data\n",
        "\n",
        "Preprocess the training data to convert the images and labels into Numpy arrays for CNN to recognize."
      ],
      "metadata": {
        "id": "V8rran8l_BBX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting paths to training and testing images\n",
        "train_fol = '/content/Human Action Recognition/train'\n",
        "test_fol = '/content/Human Action Recognition/test'\n",
        "\n",
        "# Getting paths to csv files\n",
        "train_csv = '/content/Human Action Recognition/Training_set.csv'\n",
        "test_csv = '/content/Human Action Recognition/Testing_set.csv'\n",
        "\n",
        "# Store the csv file as a Pandas dataframe\n",
        "train_data = pd.read_csv(train_csv)\n",
        "\n",
        "# Get the columns of the dataframe\n",
        "train_filenames = train_data['filename']\n",
        "train_labels = train_data['label']"
      ],
      "metadata": {
        "id": "fXgDLPAyqmI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Getting the paths to test images\n",
        "test_data = pd.read_csv(test_csv)\n",
        "test_filenames = test_data['filename']\n",
        "test_paths = []\n",
        "for i in range(len(test_data)):\n",
        "  test_paths.append(test_fol + '/' + test_filenames[i])"
      ],
      "metadata": {
        "id": "8Q04EPrIUcG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def img_splitter(img_path):\n",
        "  img = Image.open(img_path) # Get the image\n",
        "  # Split the image into its red, green and blue components and store it in an array\n",
        "  return np.asarray(img.resize((160, 160))) # Convert and store the image"
      ],
      "metadata": {
        "id": "ek08_wZPMpG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Store the preprocessed arrays of images\n",
        "converted_images = []\n",
        "\n",
        "# Go through each image and store the corresponding array\n",
        "for i in range(len(train_data)):\n",
        "  img = Image.open(os.path.join(train_fol + \"/\" + train_filenames[i])) # Get the image\n",
        "  # Split the image into its red, green and blue components and store it in an array\n",
        "  converted_images.append(np.asarray(img.resize((160, 160)))) # Convert and store the image\n",
        "\n",
        "# Convert the array into a Numpy array\n",
        "x_train = np.asarray(converted_images)"
      ],
      "metadata": {
        "id": "9mwFqYkVD9KK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the labels column in the dataframe to an array with 15 indices for each label\n",
        "y_train = to_categorical(np.asarray(train_labels.factorize()[0]))"
      ],
      "metadata": {
        "id": "-0C9UfD0LJJl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Using Pretrained Models\n",
        "\n",
        "## 1. ResNet101"
      ],
      "metadata": {
        "id": "q5AQfp2Znxz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Intializing a Sequential model\n",
        "resnet101_model = Sequential()\n",
        "\n",
        "# Getting a pretrained ResNet101 model\n",
        "pretrained_resnet101_model = tf.keras.applications.ResNet101(\n",
        "  include_top=False,\n",
        "  input_shape=(160, 160, 3),\n",
        "  pooling='avg',\n",
        "  classes=15, # Initialized the number of classes in the dataset\n",
        "  weights='imagenet'\n",
        ")\n",
        "\n",
        "# Fixing the weights of the pretrained model to avoid retraining\n",
        "for layer in pretrained_resnet101_model.layers:\n",
        "  layer.trainable = False\n",
        "\n",
        "# Adding the pretrained model and additional layers to the Sequential model\n",
        "resnet101_model.add(pretrained_resnet101_model)\n",
        "resnet101_model.add(Flatten())\n",
        "resnet101_model.add(Dense(512, activation='relu'))\n",
        "resnet101_model.add(Dense(15, activation='softmax')) # Predicts one of 15 labels"
      ],
      "metadata": {
        "id": "pNiZlWXA1Wvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compiling the model\n",
        "resnet101_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "resnet101_model.summary()"
      ],
      "metadata": {
        "id": "oLJz15e91C5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the model\n",
        "history = resnet101_model.fit(x_train, y_train, epochs=60)"
      ],
      "metadata": {
        "id": "3yf7P2j71nIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = Image.open(test_paths[9])\n",
        "a = np.asarray(test_img.resize((160, 160)))\n",
        "result = resnet101_model.predict(np.asarray([a]))\n",
        "item_index = np.where(result==np.max(result))\n",
        "print(item_index[1][0])\n",
        "\n",
        "test_img"
      ],
      "metadata": {
        "id": "wL0XJo05AcON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Failed Code for Alexnet"
      ],
      "metadata": {
        "id": "AUfiEQaGEbAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])"
      ],
      "metadata": {
        "id": "sFhy7gmPRJxu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prediction(img_path, model):\n",
        "  inp_image = Image.open(img_path)\n",
        "  inp_tensor = preprocess(inp_image)\n",
        "  inp_batch = inp_tensor.unsqueeze(0)\n",
        "  # with torch.no_grad():\n",
        "  return model(inp_batch)"
      ],
      "metadata": {
        "id": "7NXa8XIig36C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = get_prediction(test_paths[0], alexnet_model)\n",
        "probabilities = torch.nn.functional.softmax(prediction[0], dim=0)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "id": "5g5xAAJMhv1K"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}